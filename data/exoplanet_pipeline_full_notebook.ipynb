{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45037446",
   "metadata": {},
   "source": [
    "\n",
    "# Exoplanet ML Pipeline — Full (Expanded)\n",
    "\n",
    "This notebook contains a complete reproducible pipeline for the KOI / TOI / K2 catalogs:\n",
    "- Build unified dataset\n",
    "- Clean & normalize\n",
    "- Feature engineering (radius ratio, depth checks, SNR proxy, logs, HZ flag)\n",
    "- Multiple training strategies:\n",
    "  - Train/test baseline\n",
    "  - K-Fold cross-validation with CV metrics\n",
    "  - Model comparisons (RandomForest, ExtraTrees, HistGradientBoosting, LightGBM if available, Stacking)\n",
    "  - Hyperparameter tuning with Optuna (optional)\n",
    "  - Semi-supervised approach on unlabeled data (self-training)\n",
    "- Interpretability: SHAP explanations (optional)\n",
    "- Export model to ONNX and example Flask API for inference\n",
    "- Simple unit tests, Dockerfile template, and guidance for deployment\n",
    "\n",
    "**Important:** several cells (Optuna tuning, SHAP, LightGBM) require additional packages. They are optional and included behind informative cells. Run the notebook cells locally where you have stable compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b07b93",
   "metadata": {},
   "source": [
    "\n",
    "## Installation / Requirements\n",
    "\n",
    "Recommended to create and activate a virtual environment first.\n",
    "\n",
    "Optional packages (install as needed for advanced steps):\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn matplotlib nbformat\n",
    "# optional (faster gradient boosters & SHAP & Optuna & ONNX)\n",
    "pip install lightgbm optuna shap onnx onnxruntime flask gunicorn pytest\n",
    "```\n",
    "If `lightgbm` is difficult to build locally, you can omit it — the notebook will detect presence and skip related cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc18ed97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:39:25.631407Z",
     "start_time": "2025-10-03T15:39:25.628436Z"
    }
   },
   "source": [
    "\n",
    "# Core imports used throughout the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, json, pickle, math\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "BASE = Path('output')  # adjust as needed\n",
    "print('Notebook BASE:', BASE)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook BASE: output\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:39:26.503409Z",
     "start_time": "2025-10-03T15:39:26.284832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Build unified dataset (same mapping used previously) ---\n",
    "koi_file = 'cumulative_2025.09.21_17.22.39.csv'\n",
    "toi_file = 'TOI_2025.09.21_17.24.45.csv'\n",
    "k2_file  = 'k2pandc_2025.09.21_17.26.00.csv'\n",
    "\n",
    "print('Loading CSVs...')\n",
    "df_koi = pd.read_csv(koi_file)\n",
    "df_toi = pd.read_csv(toi_file)\n",
    "df_k2 = pd.read_csv(k2_file)\n",
    "\n",
    "print('KOI', df_koi.shape, 'TOI', df_toi.shape, 'K2', df_k2.shape)\n"
   ],
   "id": "2788f18582c9769e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs...\n",
      "KOI (9564, 141) TOI (7668, 87) K2 (3992, 295)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "fb50e518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:39:27.495721Z",
     "start_time": "2025-10-03T15:39:27.391419Z"
    }
   },
   "source": [
    "schema_map = {\n",
    "    'orbital_period': {'koi':'koi_period','toi':'pl_orbper','k2':'pl_orbper'},\n",
    "    'transit_duration': {'koi':'koi_duration','toi':'pl_trandurh','k2':'pl_trandur'},\n",
    "    'transit_depth': {'koi':'koi_depth','toi':'pl_trandep','k2':'pl_trandep'},\n",
    "    'planet_radius': {'koi':'koi_prad','toi':'pl_rade','k2':'pl_rade'},\n",
    "    'radius_ratio': {'koi':'koi_ror','toi':None,'k2':'pl_ratror'},\n",
    "    'stellar_teff': {'koi':'koi_steff','toi':'st_teff','k2':'st_teff'},\n",
    "    'stellar_radius': {'koi':'koi_srad','toi':'st_rad','k2':'st_rad'},\n",
    "    'stellar_mass': {'koi':'koi_smass','toi':None,'k2':'st_mass'},\n",
    "    'insolation_flux': {'koi':'koi_insol','toi':'pl_insol','k2':'pl_insol'},\n",
    "    'teq': {'koi':'koi_teq','toi':'pl_eqt','k2':'pl_eqt'},\n",
    "    'label': {'koi':'koi_disposition','toi':'tfopwg_disp','k2':'disposition'}\n",
    "}\n",
    "\n",
    "def standardize(df, mission):\n",
    "    out = {}\n",
    "    for std_col, mapping in schema_map.items():\n",
    "        src = mapping.get(mission)\n",
    "        if src and src in df.columns:\n",
    "            out[std_col] = df[src]\n",
    "        else:\n",
    "            out[std_col] = pd.Series([None]*len(df))\n",
    "    res = pd.DataFrame(out)\n",
    "    res['mission'] = mission\n",
    "    return res\n",
    "\n",
    "std_koi = standardize(df_koi, 'koi')\n",
    "std_toi = standardize(df_toi, 'toi')\n",
    "std_k2  = standardize(df_k2, 'k2')\n",
    "unified = pd.concat([std_koi, std_toi, std_k2], ignore_index=True)\n",
    "unified['mission'] = unified['mission'].map({'koi':'Kepler','toi':'TESS','k2':'K2'})\n",
    "print('Unified shape:', unified.shape)\n",
    "# save snapshot\n",
    "unified.to_csv(BASE / 'unified_exoplanets_raw_rebuilt_from_notebook.csv', index=False)\n",
    "unified.head(3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified shape: (21224, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   orbital_period  transit_duration  transit_depth  planet_radius  \\\n",
       "0        9.488036            2.9575          615.8           2.26   \n",
       "1       54.418383            4.5070          874.8           2.83   \n",
       "2       19.899140            1.7822        10829.0          14.60   \n",
       "\n",
       "   radius_ratio  stellar_teff  stellar_radius  stellar_mass  insolation_flux  \\\n",
       "0      0.022344        5455.0           0.927         0.919            93.59   \n",
       "1      0.027954        5455.0           0.927         0.919             9.11   \n",
       "2      0.154046        5853.0           0.868         0.961            39.30   \n",
       "\n",
       "     teq      label mission  \n",
       "0  793.0  CONFIRMED  Kepler  \n",
       "1  443.0  CONFIRMED  Kepler  \n",
       "2  638.0  CANDIDATE  Kepler  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>transit_duration</th>\n",
       "      <th>transit_depth</th>\n",
       "      <th>planet_radius</th>\n",
       "      <th>radius_ratio</th>\n",
       "      <th>stellar_teff</th>\n",
       "      <th>stellar_radius</th>\n",
       "      <th>stellar_mass</th>\n",
       "      <th>insolation_flux</th>\n",
       "      <th>teq</th>\n",
       "      <th>label</th>\n",
       "      <th>mission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.9575</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.022344</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.919</td>\n",
       "      <td>93.59</td>\n",
       "      <td>793.0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.5070</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.919</td>\n",
       "      <td>9.11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.7822</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.154046</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.961</td>\n",
       "      <td>39.30</td>\n",
       "      <td>638.0</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:39:28.741646Z",
     "start_time": "2025-10-03T15:39:28.731577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Clean & normalize ---\n",
    "def normalize_label(x):\n",
    "    if pd.isna(x): return None\n",
    "    txt = str(x).strip().upper()\n",
    "    if 'CONFIRM' in txt: return 'Confirmed'\n",
    "    if txt in ('CANDIDATE','PC','KP','CP','CP (COMMUNITY)'): return 'Candidate'\n",
    "    if 'FALSE' in txt or txt=='FP': return 'False Positive'\n",
    "    return txt.title()\n",
    "\n",
    "unified['label'] = unified['label'].apply(normalize_label)"
   ],
   "id": "6001052e53a0b7ec",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "ed379a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:39:50.945836Z",
     "start_time": "2025-10-03T15:39:50.873345Z"
    }
   },
   "source": [
    "def depth_to_ppm(row):\n",
    "    v = row['transit_depth']\n",
    "    try:\n",
    "        vv = float(v)\n",
    "    except:\n",
    "        return np.nan\n",
    "    if row['mission']=='K2':\n",
    "        return vv * 10000.0\n",
    "    return vv\n",
    "unified['transit_depth_ppm'] = unified.apply(depth_to_ppm, axis=1)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:43:39.426897Z",
     "start_time": "2025-10-03T15:43:39.395615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = ['orbital_period','transit_duration','transit_depth_ppm','planet_radius',\n",
    "            'radius_ratio','stellar_teff','stellar_radius','stellar_mass','insolation_flux','teq']\n",
    "\n",
    "for c in num_cols:\n",
    "    unified[c] = pd.to_numeric(unified[c], errors='coerce')\n",
    "    unified[c] = unified.groupby('mission')[c].transform(lambda g: g.fillna(g.median()))\n",
    "    unified[c] = unified[c].fillna(unified[c].median())\n"
   ],
   "id": "76a4d8d1f68451fb",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:43:42.373874Z",
     "start_time": "2025-10-03T15:43:42.263177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save cleaned\n",
    "cleaned_path = BASE / 'unified_exoplanets_cleaned_full_notebook.csv'\n",
    "unified.to_csv(cleaned_path, index=False)\n",
    "print('Saved cleaned file to', cleaned_path)\n",
    "unified[num_cols + ['label','mission']].head(5)\n"
   ],
   "id": "8c148438e9964534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned file to output/unified_exoplanets_cleaned_full_notebook.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   orbital_period  transit_duration  transit_depth_ppm  planet_radius  \\\n",
       "0        9.488036           2.95750              615.8           2.26   \n",
       "1       54.418383           4.50700              874.8           2.83   \n",
       "2       19.899140           1.78220            10829.0          14.60   \n",
       "3        1.736952           2.40641             8079.2          33.46   \n",
       "4        2.525592           1.65450              603.3           2.75   \n",
       "\n",
       "   radius_ratio  stellar_teff  stellar_radius  stellar_mass  insolation_flux  \\\n",
       "0      0.022344        5455.0           0.927         0.919            93.59   \n",
       "1      0.027954        5455.0           0.927         0.919             9.11   \n",
       "2      0.154046        5853.0           0.868         0.961            39.30   \n",
       "3      0.387394        5805.0           0.791         0.836           891.96   \n",
       "4      0.024064        6031.0           1.046         1.095           926.16   \n",
       "\n",
       "      teq           label mission  \n",
       "0   793.0       Confirmed  Kepler  \n",
       "1   443.0       Confirmed  Kepler  \n",
       "2   638.0       Candidate  Kepler  \n",
       "3  1395.0  False Positive  Kepler  \n",
       "4  1406.0       Confirmed  Kepler  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>transit_duration</th>\n",
       "      <th>transit_depth_ppm</th>\n",
       "      <th>planet_radius</th>\n",
       "      <th>radius_ratio</th>\n",
       "      <th>stellar_teff</th>\n",
       "      <th>stellar_radius</th>\n",
       "      <th>stellar_mass</th>\n",
       "      <th>insolation_flux</th>\n",
       "      <th>teq</th>\n",
       "      <th>label</th>\n",
       "      <th>mission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.022344</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.919</td>\n",
       "      <td>93.59</td>\n",
       "      <td>793.0</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.919</td>\n",
       "      <td>9.11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.154046</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.961</td>\n",
       "      <td>39.30</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.836</td>\n",
       "      <td>891.96</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>False Positive</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.024064</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1.095</td>\n",
       "      <td>926.16</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>Kepler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:45:41.250645Z",
     "start_time": "2025-10-03T15:45:41.247716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Feature engineering ---\n",
    "earth_per_sun = 695700.0/6371.0  # ~109.197\n",
    "unified['radius_ratio_calc'] = unified['planet_radius'] / (unified['stellar_radius'] * earth_per_sun)\n",
    "unified['radius_ratio_final'] = unified['radius_ratio']\n",
    "unified.loc[unified['radius_ratio_final'].isna(), 'radius_ratio_final'] = unified.loc[unified['radius_ratio_final'].isna(), 'radius_ratio_calc']\n"
   ],
   "id": "426a21a6a4a65ffa",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:45:51.743543Z",
     "start_time": "2025-10-03T15:45:51.739495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unified['transit_depth_frac'] = unified['transit_depth_ppm'] / 1e6\n",
    "unified['expected_depth_frac'] = unified['radius_ratio_final']**2\n",
    "valid = (unified['expected_depth_frac']>0) & unified['transit_depth_frac'].notna()\n",
    "unified['depth_ratio'] = np.nan\n",
    "unified.loc[valid, 'depth_ratio'] = unified.loc[valid,'transit_depth_frac'] / unified.loc[valid,'expected_depth_frac']\n",
    "unified['depth_diff'] = unified['transit_depth_frac'] - unified['expected_depth_frac']"
   ],
   "id": "8fc0805012cc5578",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:46:02.184020Z",
     "start_time": "2025-10-03T15:46:02.179649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unified['snr_proxy'] = np.nan\n",
    "mask = unified['transit_duration'].notna() & (unified['transit_duration']>0) & unified['transit_depth_ppm'].notna()\n",
    "unified.loc[mask, 'snr_proxy'] = unified.loc[mask,'transit_depth_ppm'] / np.sqrt(unified.loc[mask,'transit_duration'])"
   ],
   "id": "693b666e154703de",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:46:15.400533Z",
     "start_time": "2025-10-03T15:46:15.385478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for c in ['orbital_period','planet_radius','transit_depth_ppm','insolation_flux','teq']:\n",
    "    unified[f'log1p_{c}'] = np.log1p(unified[c].clip(lower=0).fillna(0))\n",
    "\n",
    "unified['habitable_zone_flag'] = unified['insolation_flux'].apply(lambda x: 1 if pd.notna(x) and (0.25 <= x <= 2.0) else 0)"
   ],
   "id": "293d621ebd6c474a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:47:02.628285Z",
     "start_time": "2025-10-03T15:47:02.625782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Impute engineered features by mission median then global median\n",
    "eng_feats = ['radius_ratio_final','radius_ratio_calc','transit_depth_frac','expected_depth_frac',\n",
    "             'depth_ratio','depth_diff','snr_proxy','log1p_orbital_period','log1p_planet_radius',\n",
    "             'log1p_transit_depth_ppm','log1p_insolation_flux','log1p_teq','habitable_zone_flag']\n"
   ],
   "id": "dd692a4ce1cd7ac0",
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "af495d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:48:20.034995Z",
     "start_time": "2025-10-03T15:48:19.993382Z"
    }
   },
   "source": [
    "for c in eng_feats:\n",
    "    unified[c] = pd.to_numeric(unified[c], errors='coerce')\n",
    "    unified[c] = unified.groupby('mission')[c].transform(lambda g: g.fillna(g.median()))\n",
    "    unified[c] = unified[c].fillna(unified[c].median())"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:48:21.928208Z",
     "start_time": "2025-10-03T15:48:21.915347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save engineered sample\n",
    "eng_sample = BASE / 'engineered_features_sample_full_notebook.csv'\n",
    "unified.head(200).to_csv(eng_sample, index=False)\n",
    "print('Saved engineered sample to', eng_sample)\n",
    "unified[['orbital_period','planet_radius','radius_ratio_final','transit_depth_ppm','depth_ratio','snr_proxy']].head(10)\n"
   ],
   "id": "e16f27eb59242a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved engineered sample to output/engineered_features_sample_full_notebook.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   orbital_period  planet_radius  radius_ratio_final  transit_depth_ppm  \\\n",
       "0        9.488036           2.26            0.022344              615.8   \n",
       "1       54.418383           2.83            0.027954              874.8   \n",
       "2       19.899140          14.60            0.154046            10829.0   \n",
       "3        1.736952          33.46            0.387394             8079.2   \n",
       "4        2.525592           2.75            0.024064              603.3   \n",
       "5       11.094321           3.90            0.036779             1517.5   \n",
       "6        4.134435           2.77            0.026133              686.0   \n",
       "7        2.566589           1.59            0.014983              226.5   \n",
       "8        7.361790          39.21            0.183387              233.7   \n",
       "9       16.068647           5.76            0.062161             4914.3   \n",
       "\n",
       "   depth_ratio    snr_proxy  \n",
       "0     1.233439   358.077727  \n",
       "1     1.119492   412.064305  \n",
       "2     0.456339  8111.667380  \n",
       "3     0.053835  5208.150762  \n",
       "4     1.041832   469.029263  \n",
       "5     1.121835   707.961388  \n",
       "6     1.004490   387.119868  \n",
       "7     1.008952   145.329724  \n",
       "8     0.006949   104.284643  \n",
       "9     1.271820  2613.878431  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>planet_radius</th>\n",
       "      <th>radius_ratio_final</th>\n",
       "      <th>transit_depth_ppm</th>\n",
       "      <th>depth_ratio</th>\n",
       "      <th>snr_proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.022344</td>\n",
       "      <td>615.8</td>\n",
       "      <td>1.233439</td>\n",
       "      <td>358.077727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>874.8</td>\n",
       "      <td>1.119492</td>\n",
       "      <td>412.064305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.154046</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>0.456339</td>\n",
       "      <td>8111.667380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>33.46</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>0.053835</td>\n",
       "      <td>5208.150762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.024064</td>\n",
       "      <td>603.3</td>\n",
       "      <td>1.041832</td>\n",
       "      <td>469.029263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.094321</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>1517.5</td>\n",
       "      <td>1.121835</td>\n",
       "      <td>707.961388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.134435</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>686.0</td>\n",
       "      <td>1.004490</td>\n",
       "      <td>387.119868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.566589</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>226.5</td>\n",
       "      <td>1.008952</td>\n",
       "      <td>145.329724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.361790</td>\n",
       "      <td>39.21</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>233.7</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>104.284643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.068647</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.062161</td>\n",
       "      <td>4914.3</td>\n",
       "      <td>1.271820</td>\n",
       "      <td>2613.878431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "9e4d6d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:51:00.737267Z",
     "start_time": "2025-10-03T15:49:21.795804Z"
    }
   },
   "source": [
    "\n",
    "# --- Train/test baseline (quick comparison) ---\n",
    "final_features = ['orbital_period','transit_duration','transit_depth_ppm','planet_radius',\n",
    "                  'radius_ratio_final','stellar_teff','stellar_radius','stellar_mass','insolation_flux','teq',\n",
    "                  'depth_ratio','depth_diff','snr_proxy','log1p_orbital_period','log1p_planet_radius','log1p_transit_depth_ppm','habitable_zone_flag']\n",
    "\n",
    "labeled = unified[unified['label'].notna()].copy()\n",
    "for c in final_features:\n",
    "    labeled[c] = pd.to_numeric(labeled[c], errors='coerce')\n",
    "    labeled[c] = labeled.groupby('mission')[c].transform(lambda g: g.fillna(g.median()))\n",
    "    labeled[c] = labeled[c].fillna(labeled[c].median())\n",
    "\n",
    "print('Labeled rows:', len(labeled))\n",
    "\n",
    "X = labeled[final_features].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labeled['label'].astype(str).values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42, n_jobs=1),\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=200, class_weight='balanced', random_state=42, n_jobs=1),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# optional LightGBM\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    models['LightGBM'] = lgb.LGBMClassifier(n_estimators=500, class_weight='balanced', random_state=42, n_jobs=1)\n",
    "    print('LightGBM included.')\n",
    "except Exception:\n",
    "    print('LightGBM not installed; skipping.')\n",
    "\n",
    "# stacking\n",
    "base_estimators = [('rf', models['RandomForest']), ('et', models['ExtraTrees']), ('hgb', models['HistGradientBoosting'])]\n",
    "stack = StackingClassifier(estimators=base_estimators, final_estimator=LogisticRegression(max_iter=1000), n_jobs=1)\n",
    "models['Stacking'] = stack\n",
    "\n",
    "results = {}\n",
    "for name, clf in models.items():\n",
    "    print('\\nTraining', name)\n",
    "    try:\n",
    "        clf.fit(X_train_s, y_train)\n",
    "        preds = clf.predict(X_test_s)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        report = classification_report(y_test, preds, target_names=le.classes_, digits=4)\n",
    "        conf = confusion_matrix(y_test, preds)\n",
    "        results[name] = {'accuracy': float(acc), 'report': report, 'confusion_matrix': conf.tolist()}\n",
    "        # Save model and feature importances if available\n",
    "        with open(BASE / f'model_{name.lower()}_full_notebook.pkl','wb') as f:\n",
    "            pickle.dump({'model': clf, 'label_encoder': le, 'features': final_features, 'scaler': scaler}, f)\n",
    "        if hasattr(clf, 'feature_importances_'):\n",
    "            imp = clf.feature_importances_\n",
    "            feat_imp = pd.DataFrame({'feature': final_features, 'importance': imp}).sort_values('importance', ascending=False)\n",
    "            feat_imp.to_csv(BASE / f'feature_importances_{name.lower()}_full_notebook.csv', index=False)\n",
    "            display(feat_imp.head(10))\n",
    "    except Exception as e:\n",
    "        print('Failed', name, e)\n",
    "\n",
    "with open(BASE / 'engineered_models_metrics_full_notebook.json','w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print('\\nSaved metrics to engineered_models_metrics_full_notebook.json')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled rows: 21224\n",
      "LightGBM not installed; skipping.\n",
      "\n",
      "Training RandomForest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                feature  importance\n",
       "4    radius_ratio_final    0.100469\n",
       "1      transit_duration    0.077616\n",
       "7          stellar_mass    0.071137\n",
       "14  log1p_planet_radius    0.070522\n",
       "11           depth_diff    0.070418\n",
       "3         planet_radius    0.070321\n",
       "10          depth_ratio    0.069996\n",
       "9                   teq    0.058641\n",
       "0        orbital_period    0.056668\n",
       "12            snr_proxy    0.055565"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radius_ratio_final</td>\n",
       "      <td>0.100469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transit_duration</td>\n",
       "      <td>0.077616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stellar_mass</td>\n",
       "      <td>0.071137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>log1p_planet_radius</td>\n",
       "      <td>0.070522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>depth_diff</td>\n",
       "      <td>0.070418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planet_radius</td>\n",
       "      <td>0.070321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>depth_ratio</td>\n",
       "      <td>0.069996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>teq</td>\n",
       "      <td>0.058641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orbital_period</td>\n",
       "      <td>0.056668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>snr_proxy</td>\n",
       "      <td>0.055565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ExtraTrees\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                    feature  importance\n",
       "10              depth_ratio    0.089899\n",
       "15  log1p_transit_depth_ppm    0.084181\n",
       "14      log1p_planet_radius    0.081980\n",
       "13     log1p_orbital_period    0.075477\n",
       "9                       teq    0.066552\n",
       "1          transit_duration    0.064660\n",
       "2         transit_depth_ppm    0.062730\n",
       "4        radius_ratio_final    0.062003\n",
       "12                snr_proxy    0.060664\n",
       "3             planet_radius    0.056565"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>depth_ratio</td>\n",
       "      <td>0.089899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>log1p_transit_depth_ppm</td>\n",
       "      <td>0.084181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>log1p_planet_radius</td>\n",
       "      <td>0.081980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>log1p_orbital_period</td>\n",
       "      <td>0.075477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>teq</td>\n",
       "      <td>0.066552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transit_duration</td>\n",
       "      <td>0.064660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transit_depth_ppm</td>\n",
       "      <td>0.062730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radius_ratio_final</td>\n",
       "      <td>0.062003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>snr_proxy</td>\n",
       "      <td>0.060664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planet_radius</td>\n",
       "      <td>0.056565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training HistGradientBoosting\n",
      "\n",
      "Training Stacking\n",
      "\n",
      "Saved metrics to engineered_models_metrics_full_notebook.json\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:52:11.635314Z",
     "start_time": "2025-10-03T15:52:11.630926Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "d78a5aff98377010",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'accuracy': 0.7561837455830389,\n",
       "  'report': '                precision    recall  f1-score   support\\n\\n           Apc     0.3750    0.0652    0.1111        92\\n     Candidate     0.7451    0.7809    0.7626      1853\\n     Confirmed     0.7520    0.8576    0.8013      1011\\n            Fa     0.0000    0.0000    0.0000        20\\nFalse Positive     0.7846    0.7028    0.7415      1265\\n       Refuted     1.0000    0.2500    0.4000         4\\n\\n      accuracy                         0.7562      4245\\n     macro avg     0.6095    0.4427    0.4694      4245\\n  weighted avg     0.7472    0.7562    0.7475      4245\\n',\n",
       "  'confusion_matrix': [[6, 73, 0, 0, 13, 0],\n",
       "   [8, 1447, 208, 0, 190, 0],\n",
       "   [0, 107, 867, 0, 37, 0],\n",
       "   [0, 16, 0, 0, 4, 0],\n",
       "   [2, 297, 77, 0, 889, 0],\n",
       "   [0, 2, 1, 0, 0, 1]]},\n",
       " 'ExtraTrees': {'accuracy': 0.7481743227326266,\n",
       "  'report': '                precision    recall  f1-score   support\\n\\n           Apc     0.2000    0.0326    0.0561        92\\n     Candidate     0.7411    0.7723    0.7563      1853\\n     Confirmed     0.7340    0.8516    0.7885      1011\\n            Fa     1.0000    0.0500    0.0952        20\\nFalse Positive     0.7818    0.6941    0.7353      1265\\n       Refuted     1.0000    0.5000    0.6667         4\\n\\n      accuracy                         0.7482      4245\\n     macro avg     0.7428    0.4834    0.5164      4245\\n  weighted avg     0.7413    0.7482    0.7394      4245\\n',\n",
       "  'confusion_matrix': [[3, 79, 0, 0, 10, 0],\n",
       "   [8, 1431, 224, 0, 190, 0],\n",
       "   [0, 109, 861, 0, 41, 0],\n",
       "   [0, 15, 0, 1, 4, 0],\n",
       "   [4, 297, 86, 0, 878, 0],\n",
       "   [0, 0, 2, 0, 0, 2]]},\n",
       " 'HistGradientBoosting': {'accuracy': 0.752414605418139,\n",
       "  'report': '                precision    recall  f1-score   support\\n\\n           Apc     0.2619    0.1196    0.1642        92\\n     Candidate     0.7579    0.7636    0.7608      1853\\n     Confirmed     0.7330    0.8526    0.7883      1011\\n            Fa     0.2500    0.0500    0.0833        20\\nFalse Positive     0.7902    0.7146    0.7505      1265\\n       Refuted     0.0833    0.2500    0.1250         4\\n\\n      accuracy                         0.7524      4245\\n     macro avg     0.4794    0.4584    0.4453      4245\\n  weighted avg     0.7478    0.7524    0.7475      4245\\n',\n",
       "  'confusion_matrix': [[11, 70, 0, 0, 11, 0],\n",
       "   [18, 1415, 230, 2, 183, 5],\n",
       "   [0, 105, 862, 0, 42, 2],\n",
       "   [0, 15, 0, 1, 4, 0],\n",
       "   [13, 260, 83, 1, 904, 4],\n",
       "   [0, 2, 1, 0, 0, 1]]},\n",
       " 'Stacking': {'accuracy': 0.76113074204947,\n",
       "  'report': '                precision    recall  f1-score   support\\n\\n           Apc     0.3600    0.0978    0.1538        92\\n     Candidate     0.7490    0.7858    0.7669      1853\\n     Confirmed     0.7619    0.8388    0.7985      1011\\n            Fa     0.0000    0.0000    0.0000        20\\nFalse Positive     0.7892    0.7249    0.7557      1265\\n       Refuted     1.0000    0.2500    0.4000         4\\n\\n      accuracy                         0.7611      4245\\n     macro avg     0.6100    0.4495    0.4792      4245\\n  weighted avg     0.7523    0.7611    0.7538      4245\\n',\n",
       "  'confusion_matrix': [[9, 71, 0, 0, 12, 0],\n",
       "   [10, 1456, 193, 0, 194, 0],\n",
       "   [0, 129, 848, 0, 34, 0],\n",
       "   [0, 15, 0, 0, 5, 0],\n",
       "   [6, 271, 71, 0, 917, 0],\n",
       "   [0, 2, 1, 0, 0, 1]]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2521c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- K-Fold cross-validation (Stratified) ---\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = {}\n",
    "for name, clf in [('RandomForest', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42))]:\n",
    "    print('\\nRunning CV for', name)\n",
    "    scores = cross_val_score(clf, scaler.transform(X), y, cv=kf, scoring='accuracy', n_jobs=1)\n",
    "    cv_results[name] = {'mean_accuracy': float(scores.mean()), 'std': float(scores.std()), 'fold_scores': scores.tolist()}\n",
    "    print(f\"{name} CV mean acc: {scores.mean():.4f} +- {scores.std():.4f}\")\n",
    "\n",
    "# Save CV results\n",
    "with open(BASE / 'cv_results_full_notebook.json','w') as f:\n",
    "    json.dump(cv_results, f, indent=2)\n",
    "print('Saved CV results to cv_results_full_notebook.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab4b21",
   "metadata": {},
   "source": [
    "\n",
    "## SHAP Interpretability (optional / heavy)\n",
    "\n",
    "Below cell uses SHAP to explain tree models. Install `shap` if you want to run it. SHAP can be slow for large datasets — run on a sample if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551243ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- SHAP explanation for RandomForest (optional) ---\n",
    "try:\n",
    "    import shap\n",
    "    model_path = BASE / 'model_randomforest_full_notebook.pkl'\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "        rf = obj['model']\n",
    "        # use a small sample to compute SHAP values\n",
    "        sample_idx = np.random.choice(range(X_train_s.shape[0]), size=min(500, X_train_s.shape[0]), replace=False)\n",
    "        X_sample = X_train_s[sample_idx]\n",
    "        explainer = shap.TreeExplainer(rf)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        # summary plot (multi-class will have a list of arrays)\n",
    "        try:\n",
    "            shap.summary_plot(shap_values, X_sample, feature_names=final_features)\n",
    "        except Exception as e:\n",
    "            print('Could not display SHAP plot:', e)\n",
    "    else:\n",
    "        print('RandomForest model not found at', model_path)\n",
    "except Exception as e:\n",
    "    print('SHAP not available or failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082473be",
   "metadata": {},
   "source": [
    "\n",
    "## Optuna hyperparameter tuning (optional / heavy)\n",
    "\n",
    "The cell below will run Optuna to tune LightGBM (if available) or RandomForest. This can be time-consuming — adjust `n_trials` and `timeout` for faster runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87630348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optuna hyperparameter tuning example (lightweight) ---\n",
    "try:\n",
    "    import optuna\n",
    "    def objective_rf(trial):\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight='balanced', random_state=42, n_jobs=1)\n",
    "        scores = cross_val_score(clf, scaler.transform(X), y, cv=3, scoring='accuracy', n_jobs=1)\n",
    "        return float(scores.mean())\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    print('Starting Optuna study (RF) — reduce n_trials if this is slow')\n",
    "    study.optimize(objective_rf, n_trials=20, timeout=None)\n",
    "    print('Best trial:', study.best_trial.params, 'value:', study.best_trial.value)\n",
    "    with open(BASE / 'optuna_rf_study_full_notebook.pkl','wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "except Exception as e:\n",
    "    print('Optuna not available or tuning failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Semi-supervised: Self-training classifier on unlabeled data (scikit-learn) ---\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "# requires a base estimator; we'll use RandomForest but set probability=True via wrapper or use ExtraTrees\n",
    "base = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "self_trainer = SelfTrainingClassifier(base)\n",
    "# Prepare X_full (labeled + unlabeled)\n",
    "all_df = unified.copy()\n",
    "# Ensure features present\n",
    "for c in final_features:\n",
    "    all_df[c] = pd.to_numeric(all_df[c], errors='coerce')\n",
    "    all_df[c] = all_df.groupby('mission')[c].apply(lambda g: g.fillna(g.median()))\n",
    "    all_df[c] = all_df[c].fillna(all_df[c].median())\n",
    "\n",
    "X_all = all_df[final_features].values\n",
    "label_mask = all_df['label'].notna()\n",
    "y_all = np.where(label_mask, LabelEncoder().fit_transform(all_df.loc[label_mask,'label'].astype(str).values), -1)\n",
    "\n",
    "print('Total rows:', len(X_all), 'Labeled:', label_mask.sum(), 'Unlabeled:', (~label_mask).sum())\n",
    "\n",
    "# Fit self-training (this may take time)\n",
    "try:\n",
    "    self_trainer.fit(X_all, y_all)\n",
    "    # Save semi-supervised model\n",
    "    with open(BASE / 'self_training_model_full_notebook.pkl','wb') as f:\n",
    "        pickle.dump({'model': self_trainer, 'features': final_features}, f)\n",
    "    print('Self-training complete and saved.')\n",
    "except Exception as e:\n",
    "    print('Self-training failed or slow:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Export a tree model (RandomForest) to ONNX (optional) ---\n",
    "try:\n",
    "    import skl2onnx\n",
    "    from skl2onnx import convert_sklearn\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    model_path = BASE / 'model_randomforest_full_notebook.pkl'\n",
    "    if model_path.exists():\n",
    "        with open(model_path, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "        rf = obj['model']\n",
    "        initial_type = [('float_input', FloatTensorType([None, len(final_features)]))]\n",
    "        onnx_model = convert_sklearn(rf, initial_types=initial_type)\n",
    "        with open(BASE / 'model_randomforest_full_notebook.onnx','wb') as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        print('ONNX model saved to model_randomforest_full_notebook.onnx')\n",
    "    else:\n",
    "        print('RandomForest model file not found to export. Run training cell first.')\n",
    "except Exception as e:\n",
    "    print('ONNX export failed (skl2onnx may not be installed):', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example Flask app for model inference (create file app_inference.py) ---\n",
    "flask_code = r\"\"\"from flask import Flask, request, jsonify\n",
    "import pickle, numpy as np\n",
    "from pathlib import Path\n",
    "app = Flask(__name__)\n",
    "MODEL_PATH = Path('model_randomforest_full_notebook.pkl')\n",
    "\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "model = obj['model']\n",
    "le = obj['label_encoder']\n",
    "features = obj['features']\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    # expect data to be a dict with feature names matching 'features'\n",
    "    x = [float(data.get(fe, 0.0)) for fe in features]\n",
    "    import numpy as np\n",
    "    proba = model.predict_proba([x])[0].tolist()\n",
    "    pred = int(model.predict([x])[0])\n",
    "    label = le.inverse_transform([pred])[0]\n",
    "    return jsonify({'prediction': label, 'probabilities': proba})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\"\"\"\n",
    "open(BASE / 'app_inference.py','w').write(flask_code)\n",
    "print('Wrote example Flask app to', BASE / 'app_inference.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad38ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Minimal unit tests using pytest style (writes tests/test_pipeline.py) ---\n",
    "test_code = '''\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def test_cleaned_exists():\n",
    "    p = Path('unified_exoplanets_cleaned_full_notebook.csv')\n",
    "    assert p.exists(), \"Cleaned CSV not found\"\n",
    "\n",
    "def test_engineered_sample_exists():\n",
    "    p = Path('engineered_features_sample_full_notebook.csv')\n",
    "    assert p.exists(), \"Engineered sample not found\"\n",
    "'''\n",
    "tests_dir = BASE / 'tests'\n",
    "tests_dir.mkdir(exist_ok=True)\n",
    "open(tests_dir / 'test_pipeline.py','w').write(test_code)\n",
    "print('Wrote simple pytest tests to', tests_dir / 'test_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e13374",
   "metadata": {},
   "source": [
    "\n",
    "## Dockerfile template (example)\n",
    "\n",
    "Below is a simple Dockerfile you can use as a starting point to containerize the inference app.\n",
    "\n",
    "```\n",
    "FROM python:3.11-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt ./\n",
    "RUN pip install -r requirements.txt\n",
    "COPY app_inference.py ./\n",
    "COPY model_randomforest_full_notebook.pkl ./\n",
    "EXPOSE 5000\n",
    "CMD [\"gunicorn\", \"-b\", \"0.0.0.0:5000\", \"app_inference:app\"]\n",
    "```\n",
    "Create a `requirements.txt` with the required runtime packages (Flask, scikit-learn, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c08dd",
   "metadata": {},
   "source": [
    "\n",
    "## Benchmark comparison (template)\n",
    "\n",
    "This cell is a template: you can paste benchmark numbers from literature (e.g., AUC, accuracy) and the notebook will compare our model metrics to those.\n",
    "\n",
    "If you want me to fetch benchmark numbers from specific papers, tell me which papers and I can add code to pull and parse them (requires web access).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example: load our metrics and compare to user-provided benchmarks ---\n",
    "metrics_path = BASE / 'engineered_models_metrics_full_notebook.json'\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path,'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    print('Our model keys:', list(metrics.keys()))\n",
    "else:\n",
    "    print('Metrics file not found:', metrics_path)\n",
    "\n",
    "# Example placeholder for literature benchmarks\n",
    "literature = {\n",
    "    'paper_A': {'metric':'accuracy','value':0.85, 'note':'Example benchmark — replace with real numbers'},\n",
    "    'paper_B': {'metric':'accuracy','value':0.78, 'note':'Example benchmark'}\n",
    "}\n",
    "\n",
    "print('\\nComparison (example):')\n",
    "for model, res in metrics.items() if 'metrics' in locals() else []:\n",
    "    try:\n",
    "        print(model, 'accuracy:', res['accuracy'])\n",
    "    except:\n",
    "        print('Model', model, 'no accuracy field')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ef40b",
   "metadata": {},
   "source": [
    "\n",
    "### Notebook complete\n",
    "\n",
    "This notebook includes everything requested: robust preprocessing, engineered features, CV & train/test modeling, SHAP hooks, Optuna tuning, semi-supervised self-training, ONNX export, Flask inference example, tests, and Dockerfile template.\n",
    "\n",
    "**Notes & caveats:**\n",
    "- Some cells (Optuna, SHAP, LightGBM, ONNX export) require extra packages — install them if you plan to run those sections.\n",
    "- Long training/hyperparameter tuning should be run on a machine with enough CPU/RAM. For heavy jobs, consider using a cloud instance.\n",
    "- If you'd like, I can also generate a shorter script that runs only the parts you select (e.g., training + SHAP), or prepare a small demo Docker image build script.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
